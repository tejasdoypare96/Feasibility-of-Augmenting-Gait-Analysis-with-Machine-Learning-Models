{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5dWNCD64hVMO9QjqfP4hT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HdqwRZNBiWiD","executionInfo":{"status":"ok","timestamp":1740686269327,"user_tz":-330,"elapsed":21376,"user":{"displayName":"Tejas Doypare","userId":"16215731258952608786"}},"outputId":"cf737817-7c4e-41a7-d6b5-200edf0735ce"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n","Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.21 sounddevice-0.5.1\n"]}]},{"cell_type":"code","source":["def calculate_scaling_factor(self, virtual_points):\n","        \"\"\"\n","        Function 2:\n","        - Calculates the scaling factor using two corresponding points.\n","        - Uses the first two detected virtual points and the first two physical points from P_A.\n","        Returns the scaling factor (cm per pixel).\n","        \"\"\"\n","        if virtual_points.shape[0] < 2:\n","            raise ValueError(\"Not enough virtual points detected for scaling factor calculation.\")\n","        virtual_p1 = np.array(virtual_points[0])\n","        virtual_p2 = np.array(virtual_points[1])\n","        physical_p1 = self.P_A[:, 0]  # First physical point (column)\n","        physical_p2 = self.P_A[:, 1]  # Second physical point\n","        virtual_distance = np.linalg.norm(virtual_p2 - virtual_p1)\n","        physical_distance = np.linalg.norm(physical_p2 - physical_p1)\n","        return physical_distance / virtual_distance\n"],"metadata":{"id":"VhN1eQbVHeUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## to calculating scaling factor\n","\n","import numpy as np\n","\n","\n","# Define the coordinates\n","virtual_point_7 = np.array([0, 1802, 1161])\n","virtual_point_8 = np.array([0, 660, 2343])\n","\n","\n","physical_point_14 = np.array([0,112, 194])\n","physical_point_15 = np.array([0,112,166])\n","\n","# Calculate Euclidean distance in virtual coordinates (pixels)\n","virtual_distance = np.linalg.norm(virtual_point_7 - virtual_point_8)\n","\n","# Calculate Euclidean distance in physical coordinates (cm)\n","physical_distance = np.linalg.norm(physical_point_14 - physical_point_15)\n","\n","# Calculate the scaling factor\n","scaling_factor = physical_distance / virtual_distance\n","\n","virtual_distance, physical_distance, scaling_factor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Qk4B8hCHov1","executionInfo":{"status":"ok","timestamp":1740688703119,"user_tz":-330,"elapsed":64,"user":{"displayName":"Tejas Doypare","userId":"16215731258952608786"}},"outputId":"636a2b07-2bbd-44ab-b001-698a5714fd40"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1643.5595517047748, 28.0, 0.017036194381248385)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","###############################################\n","# CLASS 1: Processing the Static Poster (A)  #\n","###############################################\n","class PosterAProcessor:\n","    def __init__(self):\n","        # Physical coordinates for the 15 black dots on Poster A (given manually)\n","        # Each point is (0, y, z) – stored as columns in a 3x15 matrix.\n","        self.P_A = np.array([\n","            (0, 154, 222),\n","            (0, 154, 194),\n","            (0, 154, 166),\n","            (0, 147, 208),\n","            (0, 147, 180),\n","            (0, 133, 222),\n","            (0, 133, 208),\n","            (0, 133, 194),\n","            (0, 133, 180),\n","            (0, 133, 166),\n","            (0, 119, 208),\n","            (0, 119, 180),\n","            (0, 112, 222),\n","            (0, 112, 194),\n","            (0, 112, 166)\n","        ]).T  # Shape: (3, 15)\n","        # Default scale factor; in practice, you will compute this from two corresponding points.\n","        self.scale_factor_A = 0.017\n","\n","    def detect_black_points(self, image_path):\n","        \"\"\"\n","        Function 1:\n","        - Reads an input image.\n","        - Processes the image to detect the 15 black dots on Poster A.\n","        - Converts the detected centroids into the required format: (0, y, z)\n","        - Overlays red circles and blue numbering for visualization.\n","        Returns an array of virtual points (shape: (15, 3)).\n","        \"\"\"\n","        # Load the input image\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            raise ValueError(\"Error: Image not found or cannot be loaded.\")\n","\n","        # Convert the image to grayscale\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # Crop the region of interest (ROI) where the poster is likely located\n","        height, width = gray.shape\n","        roi = gray[int(height * 0.2):int(height * 0.8), int(width * 0.2):int(width * 0.8)]\n","        offset_y = int(height * 0.2)\n","        offset_x = int(width * 0.2)\n","\n","        # Apply Gaussian blur to reduce noise\n","        blurred = cv2.GaussianBlur(roi, (5, 5), 0)\n","\n","        # Threshold to isolate black points on the white poster\n","        _, binary = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV)\n","\n","        # Detect contours from the binary image\n","        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","        # Prepare a list to store the coordinates of the detected black points\n","        # For Poster A, format as (0, y, z) where image x is interpreted as z.\n","        coordinates = []\n","        for contour in contours:\n","            area = cv2.contourArea(contour)\n","            if 100 < area < 1000:  # Filter out noise and overly large areas\n","                perimeter = cv2.arcLength(contour, True)\n","                approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n","                if len(approx) >= 4:\n","                    M = cv2.moments(contour)\n","                    if M[\"m00\"] != 0:\n","                        cX = int(M[\"m10\"] / M[\"m00\"]) + offset_x\n","                        cY = int(M[\"m01\"] / M[\"m00\"]) + offset_y\n","                        # Format as (0, y, z)\n","                        coordinates.append((0, cY, cX))\n","\n","        # Sort the coordinates by y then by z (top-to-bottom, left-to-right)\n","        coordinates.sort(key=lambda point: (point[1], point[2]))\n","        # Limit to 15 points\n","        coordinates = coordinates[:15]\n","\n","        # Annotate points on the image for visualization\n","        for idx, (a, y, z) in enumerate(coordinates):\n","            cv2.circle(image, (z, y), 5, (0, 0, 255), -1)  # Red circle\n","            cv2.putText(image, f\"{idx + 1}\", (z - 10, y - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n","\n","        output_path = image_path.replace(\".png\", \"_processed.png\")\n","        cv2.imwrite(output_path, image)\n","        print(f\"Processed image saved at: {output_path}\")\n","        for idx, (a, y, z) in enumerate(coordinates):\n","            print(f\"Point {idx + 1}: (0, {y}, {z})\")\n","\n","        cv2_imshow(image)\n","        virtual_points = np.array(coordinates)\n","        return virtual_points\n","\n","    def calculate_scaling_factor(self, virtual_points):\n","        \"\"\"\n","        Function 2:\n","        - Calculates the scaling factor using two corresponding points.\n","        - Uses the first two detected virtual points and the first two physical points from P_A.\n","        Returns the scaling factor (physical units per pixel).\n","        \"\"\"\n","        if virtual_points.shape[0] < 2:\n","            raise ValueError(\"Not enough virtual points detected for scaling factor calculation.\")\n","        virtual_p1 = np.array(virtual_points[0])\n","        virtual_p2 = np.array(virtual_points[1])\n","        physical_p1 = self.P_A[:, 0]  # First physical point (column)\n","        physical_p2 = self.P_A[:, 1]  # Second physical point\n","        virtual_distance = np.linalg.norm(virtual_p2 - virtual_p1)\n","        physical_distance = np.linalg.norm(physical_p2 - physical_p1)\n","        return physical_distance / virtual_distance\n","\n","    def compute_RT(self, virtual_points, scale_factor):\n","        \"\"\"\n","        Function 3:\n","        - Converts virtual points to centimeters using the scaling factor.\n","        - Computes the centroids of the scaled virtual points (Q) and the physical points (P_A).\n","        - Constructs the covariance matrix and applies SVD.\n","        - Calculates the rotation matrix (R) and translation vector (T) such that Q ≈ R * P_A + T.\n","        Returns R and T.\n","        \"\"\"\n","        Q = (virtual_points * scale_factor).T  # Shape: (3, 15)\n","        P = self.P_A  # Physical coordinates (3,15)\n","        Q_bar = np.mean(Q, axis=1, keepdims=True)\n","        P_bar = np.mean(P, axis=1, keepdims=True)\n","        Cov = (P - P_bar) @ (Q - Q_bar).T\n","        U, S, Vt = np.linalg.svd(Cov)\n","        R = Vt.T @ U.T\n","        if np.linalg.det(R) < 0:\n","            Vt[-1, :] *= -1\n","            R = Vt.T @ U.T\n","        T = Q_bar - R @ P_bar\n","        return R, T\n","\n","    def visualize_transformation(self, image_path, R, T, scale_factor):\n","        \"\"\"\n","        Function 4:\n","        - Uses R and T to transform the physical coordinates (P_A) into virtual coordinates.\n","        - Q_hat = (R @ P_A) + T; then converts Q_hat back to pixel units by dividing by scale_factor.\n","        - The output format is (0, y, x) for Poster A.\n","        - Overlays these red points on the original image for visualization.\n","        Returns the computed virtual coordinates from physical data.\n","        \"\"\"\n","        Q_hat = (R @ self.P_A) + T  # Shape: (3, 15)\n","        Q_hat = Q_hat / scale_factor  # Convert back to pixel units\n","        virtual_from_physical = []\n","        for i in range(Q_hat.shape[1]):\n","            a = Q_hat[0, i]\n","            y = Q_hat[1, i]\n","            x = Q_hat[2, i]\n","            virtual_from_physical.append((0, y, x))\n","        virtual_from_physical = np.array(virtual_from_physical)\n","\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            raise ValueError(f\"Error: Could not load image from {image_path}\")\n","        for i, (a, y, x) in enumerate(virtual_from_physical):\n","            cv2.circle(image, (int(x), int(y)), 5, (0, 0, 255), -1)\n","            cv2.putText(image, str(i+1), (int(x)-10, int(y)-10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n","        cv2_imshow(image)\n","        cv2.imwrite('posterA_transformation_visualization.jpg', image)\n","        return virtual_from_physical\n","\n","\n"],"metadata":{"id":"ae-7XP8UFA7c","executionInfo":{"status":"ok","timestamp":1740689803203,"user_tz":-330,"elapsed":91,"user":{"displayName":"Tejas Doypare","userId":"16215731258952608786"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# ----------------- USAGE EXAMPLE ----------------- #\n","# Provide the correct image path (adjust the file extension as needed)\n","image_path = '/content/poster_A.jpg'  # Replace with your actual image path\n","\n","# Create an instance of PosterAProcessor\n","posterA = PosterAProcessor()\n","\n","# Function 1: Detect 15 virtual black points on Poster A.\n","virtual_points = posterA.detect_black_points(image_path)\n","print(\"Detected Virtual Points (Poster A):\")\n","print(virtual_points)\n","\n","# Function 2: Calculate the scaling factor using the detected virtual points.\n","# scale_factor = posterA.calculate_scaling_factor(virtual_points)\n","# print(\"Calculated Scaling Factor:\", scale_factor)\n","\n","# Optionally, you can override the computed scale factor with a known value:\n","scale_factor = 0.083  #posterA.scale_factor_A\n","\n","# Function 3: Compute R and T using the virtual points and scale factor.\n","R, T = posterA.compute_RT(virtual_points, scale_factor)\n","print(\"Computed R:\")\n","print(R)\n","print(\"Computed T:\")\n","print(T)\n","\n","# Function 4: Visualize the transformation (mapping physical coordinates back to virtual coordinates).\n","virtual_from_physical = posterA.visualize_transformation(image_path, R, T, scale_factor)\n","print(\"Virtual Coordinates from Physical (Poster A):\")\n","print(virtual_from_physical)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1v4ajec5bmwL2hgcXMalm84_IuRA36DW3"},"id":"avn-iyteMnD5","executionInfo":{"status":"ok","timestamp":1740690093311,"user_tz":-330,"elapsed":35088,"user":{"displayName":"Tejas Doypare","userId":"16215731258952608786"}},"outputId":"1aea9a28-e57e-45ad-c82d-35cdae3a6205"},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Kytznsk_iP5r","executionInfo":{"status":"error","timestamp":1740690264852,"user_tz":-330,"elapsed":49,"user":{"displayName":"Tejas Doypare","userId":"16215731258952608786"}},"outputId":"c61030f0-c4ee-4b81-becd-46d82b841c8d"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'PosterAProcessor' object has no attribute 'detect_black_dots'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-40d3e1843160>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Function 1: Detect 15 virtual black dots on Poster A.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mvirtual_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterA_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_black_dots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path_posterA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Detected Virtual Points (Poster A):\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvirtual_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PosterAProcessor' object has no attribute 'detect_black_dots'"]}],"source":["\n","\n","###############################################\n","# CLASS 2: Processing Person Joint Landmarks  #\n","###############################################\n","class PosterAJointProcessor(PosterAProcessor):\n","    def __init__(self):\n","        self.mp_pose = mp.solutions.pose\n","        self.pose = self.mp_pose.Pose(min_detection_confidence=0.5,\n","                                      min_tracking_confidence=0.5)\n","\n","    def detect_and_visualize_joints(self, image_path):\n","        \"\"\"\n","        Function 1:\n","        - Uses MediaPipe Pose to detect 7 joint locations from an image containing a person.\n","        - You can select specific landmark indices (for example, [11, 12, 23, 24, 25, 26, 28]).\n","        - Visualizes the detected joints by overlaying red circles and blue labels.\n","        Returns an array of 7 virtual joint coordinates in 2D pixel space (x, y).\n","        \"\"\"\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            raise ValueError(\"Error: Image not found or cannot be loaded.\")\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        result = self.pose.process(image_rgb)\n","\n","        desired_indices = [11, 12, 23, 24, 25, 26, 28]  # Modify as needed\n","        joints = []\n","        if result.pose_landmarks:\n","            for idx, landmark in enumerate(result.pose_landmarks.landmark):\n","                if idx in desired_indices:\n","                    x = int(landmark.x * image.shape[1])\n","                    y = int(landmark.y * image.shape[0])\n","                    joints.append((x, y))\n","                    cv2.circle(image, (x, y), 5, (0, 0, 255), -1)\n","                    cv2.putText(image, str(idx), (x-10, y-10),\n","                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n","        else:\n","            print(\"No landmarks detected.\")\n","        cv2_imshow(image)\n","        cv2.imwrite('posterA_joints_detected.jpg', image)\n","        return np.array(joints)\n","\n","    def map_joints_to_physical(self, virtual_joints, R, T, scale_factor):\n","        \"\"\"\n","        Function 2 & 3:\n","        - Converts 2D virtual joint coordinates into 3D virtual points by adding a zero for the missing dimension,\n","          forming (0, y, x) for Poster A.\n","        - Then maps these 3D virtual points to 3D physical coordinates using the transformation parameters.\n","        Returns the physical 3D coordinates for the 7 joints.\n","        \"\"\"\n","        # Augment 2D joints to 3D points: (0, y, x)\n","        virtual_3d = []\n","        for (x, y) in virtual_joints:\n","            virtual_3d.append((0, y, x))\n","        virtual_3d = np.array(virtual_3d)\n","\n","        # Apply the transformation: physical = R_inv * ( (virtual_3d * scale_factor) - T )\n","        R_inv = np.linalg.inv(R)\n","        Q_scaled = virtual_3d * scale_factor\n","        Q_translated = Q_scaled.T - T\n","        physical_joints = (R_inv @ Q_translated).T\n","        return physical_joints\n","\n","#############################\n","# USAGE EXAMPLE           #\n","#############################\n","# For Poster A (Static Poster Processing)\n","image_path_posterA = '/content/IMG-A1.jpg'  # Replace with your actual image path for Poster A\n","\n","posterA_proc = PosterAProcessor()\n","\n","# Function 1: Detect 15 virtual black dots on Poster A.\n","virtual_points = posterA_proc.detect_black_dots(image_path_posterA)\n","print(\"Detected Virtual Points (Poster A):\\n\", virtual_points)\n","\n","# Function 2: Calculate scaling factor using the first two detected virtual points and corresponding physical points.\n","if virtual_points.shape[0] < 2:\n","    print(\"Not enough points detected for scaling factor; using default.\")\n","    scale_factor = posterA_proc.scale_factor_A\n","else:\n","    scale_factor = posterA_proc.calculate_scaling_factor(virtual_points)\n","print(\"Calculated Scaling Factor:\", scale_factor)\n","\n","# Function 3: Compute R and T using SVD between the scaled virtual points and the known physical coordinates.\n","R, T = posterA_proc.compute_RT(virtual_points, scale_factor)\n","print(\"Computed R:\\n\", R)\n","print(\"Computed T:\\n\", T)\n","\n","# Function 4: Visualize the transformation by mapping physical coordinates (P_A) into virtual coordinates.\n","virtual_from_physical = posterA_proc.visualize_transformation(image_path_posterA, R, T, scale_factor)\n","print(\"Virtual Coordinates from Physical (Poster A):\\n\", virtual_from_physical)\n","\n","# For Poster A Joint Processing (Person with joints)\n","image_path_joints = '/content/IMG-A2.jpg'  # Replace with your image path containing a person\n","posterA_joint_proc = PosterAJointProcessor()\n","\n","# Function 1 (Class 2): Detect and visualize 7 joint landmarks.\n","virtual_joints = posterA_joint_proc.detect_and_visualize_joints(image_path_joints)\n","print(\"Detected Virtual Joint Points:\\n\", virtual_joints)\n","\n","# Functions 2 & 3 (Class 2): Map the detected virtual joints to 3D physical coordinates.\n","physical_joints = posterA_joint_proc.map_joints_to_physical(virtual_joints, R, T, scale_factor)\n","print(\"Mapped Physical Joint Coordinates:\\n\", physical_joints)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"hZOoiCJjE5Pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G55pW7LAE5Mc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_6R2gX8HE5J7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lIF90qkLE5Hi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PBsCOE9TE5Dl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0xWkPcgEE4-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hr4rmukUE478"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r5brNzM_E454"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PosterBProcessor:\n","    def __init__(self):\n","        self.mp_pose = mp.solutions.pose\n","        self.pose = self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n","        self.mp_draw = mp.solutions.drawing_utils\n","\n","    def detect_landmarks(self, image):\n","        \"\"\"Detects landmarks in an image for Poster B.\"\"\"\n","        if image is None:\n","            raise ValueError(\"Error: Image not found or cannot be loaded.\")\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        result = self.pose.process(image_rgb)\n","        virtual_points = []\n","        if result.pose_landmarks:\n","            for idx, landmark in enumerate(result.pose_landmarks.landmark):\n","                x = int(landmark.x * image.shape[1])\n","                y = int(landmark.y * image.shape[0])\n","                virtual_points.append((x, y, 0))  # Format (x, y, 0)\n","        return np.array(virtual_points)\n","\n","    def calculate_scaling_factor(self, virtual_p1, virtual_p2, physical_p1, physical_p2):\n","        \"\"\"Calculates the scaling factor from virtual to physical coordinates.\"\"\"\n","        virtual_distance = np.linalg.norm(virtual_p2 - virtual_p1)\n","        physical_distance = np.linalg.norm(physical_p2 - physical_p1)\n","        return physical_distance / virtual_distance\n","\n","\n","    P_B = np.array([\n","        (62, 154, 0),\n","        (90,154 , 0),\n","        (118, 154, 0),\n","        (76, 147, 0),\n","        (104, 147, 0),\n","        (62, 133, 0),\n","        (76, 133, 0),\n","        (90, 133, 0),\n","        (104, 133, 0),\n","        (118, 133, 0),\n","        (76, 119, 0),\n","        (104, 119, 0),\n","        (62, 112, 0),\n","        (90, 112, 0),\n","        (118, 112, 0)\n","    ]).T\n","    def calculate_RT(self, P_B):\n","        \"\"\"Calculates R and T matrices for transformation.\"\"\"\n","        R = np.identity(3)  # Placeholder\n","        T = np.zeros((3, 1))  # Placeholder\n","        return R, T\n","\n"],"metadata":{"id":"GGFbGRnsjjxA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CoordinateFusion:\n","    def convert_virtual_to_physical(self, R, T, Q, scale_factor):\n","        \"\"\"Converts virtual points Q to physical coordinates P.\"\"\"\n","        R_inv = np.linalg.inv(R)\n","        Q_scaled = Q * scale_factor\n","        Q_translated = Q_scaled.T - T\n","        P = (R_inv @ Q_translated).T\n","        return P\n","\n","    def fuse_3D_coordinates(self, P1, P2):\n","        \"\"\"Fuses coordinates from both posters into a single 3D representation.\"\"\"\n","        return np.column_stack((P2[:, 0], P1[:, 1], P1[:, 2]))"],"metadata":{"id":"Y8hn6GlpjlzU"},"execution_count":null,"outputs":[]}]}